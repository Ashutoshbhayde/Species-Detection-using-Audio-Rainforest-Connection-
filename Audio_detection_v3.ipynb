{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18192,
     "status": "ok",
     "timestamp": 1627650956700,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "cUuzJWL0A6Of",
    "outputId": "56c64010-bc6b-4ed5-d30c-0a267bd1dd39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 22.7 MB 1.7 MB/s \n",
      "\u001b[K     |████████████████████████████████| 2.3 MB 44.4 MB/s \n",
      "\u001b[?25hCollecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679 kB)\n",
      "\u001b[K     |████████████████████████████████| 679 kB 4.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
      "Installing collected packages: tensorflow-addons\n",
      "Successfully installed tensorflow-addons-0.13.0\n",
      "Collecting git+https://github.com/qubvel/classification_models.git\n",
      "  Cloning https://github.com/qubvel/classification_models.git to /tmp/pip-req-build-me4nk487\n",
      "  Running command git clone -q https://github.com/qubvel/classification_models.git /tmp/pip-req-build-me4nk487\n",
      "  Running command git submodule update --init --recursive -q\n",
      "Collecting keras_applications<=1.0.8,>=1.0.7\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 2.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (1.19.5)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (1.5.2)\n",
      "Building wheels for collected packages: image-classifiers\n",
      "  Building wheel for image-classifiers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for image-classifiers: filename=image_classifiers-1.0.0-py3-none-any.whl size=20045 sha256=9c18a9bbe98d62d898be779e44557ad11c6ab5229fd94594091ba56035024b0c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-12l13y83/wheels/0b/96/56/27b17c903efc647c51e4f364bfc20aa67f8d3dccad63c4fb4e\n",
      "Successfully built image-classifiers\n",
      "Installing collected packages: keras-applications, image-classifiers\n",
      "Successfully installed image-classifiers-1.0.0 keras-applications-1.0.8\n"
     ]
    }
   ],
   "source": [
    "! pip install -q tensorflow-io\n",
    "! pip install tensorflow-addons\n",
    "! pip install git+https://github.com/qubvel/classification_models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "bywuQ5IHIGpX",
    "outputId": "5ac7fafa-99f0-4501-882c-e07aee96cc82"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27806,
     "status": "ok",
     "timestamp": 1627650857806,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "cxQPYDCLsgcU",
    "outputId": "4b349a8a-66e7-491b-e44d-dd301cceb094"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6745,
     "status": "ok",
     "timestamp": 1627650963378,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "3QEHux8hXhNu",
    "outputId": "10d31448-a9a4-4c1a-a8c8-840d9b69fb63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "!pip install tqdm\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from tensorflow.keras.layers import Input, LSTM,GlobalAveragePooling2D, Dense,GlobalAveragePooling1D,MaxPooling2D,Dropout,BatchNormalization,Conv2D,Conv1D,MaxPooling1D,Activation,Concatenate,Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import tensorflow_addons as tfa\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from classification_models.keras import Classifiers\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 737,
     "status": "ok",
     "timestamp": 1627634235716,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "TynLsz-4S30I",
    "outputId": "de7b8d9d-5508-4499-95ef-1d8e4b1cd218"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recording_id</th>\n",
       "      <th>species_id</th>\n",
       "      <th>songtype_id</th>\n",
       "      <th>t_min</th>\n",
       "      <th>f_min</th>\n",
       "      <th>t_max</th>\n",
       "      <th>f_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003bec244</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>44.5440</td>\n",
       "      <td>2531.250</td>\n",
       "      <td>45.1307</td>\n",
       "      <td>5531.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>006ab765f</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>39.9615</td>\n",
       "      <td>7235.160</td>\n",
       "      <td>46.0452</td>\n",
       "      <td>11283.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>007f87ba2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>39.1360</td>\n",
       "      <td>562.500</td>\n",
       "      <td>42.2720</td>\n",
       "      <td>3281.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0099c367b</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>51.4206</td>\n",
       "      <td>1464.260</td>\n",
       "      <td>55.1996</td>\n",
       "      <td>4565.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>009b760e6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0854</td>\n",
       "      <td>947.461</td>\n",
       "      <td>52.5293</td>\n",
       "      <td>10852.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>fe8d9ac40</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>53.4720</td>\n",
       "      <td>93.750</td>\n",
       "      <td>54.0960</td>\n",
       "      <td>843.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>fea6b438a</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>43.5787</td>\n",
       "      <td>2531.250</td>\n",
       "      <td>45.7653</td>\n",
       "      <td>4031.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>ff2eb9ce5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.2267</td>\n",
       "      <td>5906.250</td>\n",
       "      <td>16.0213</td>\n",
       "      <td>8250.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>ffb8d8391</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>14.3467</td>\n",
       "      <td>4781.250</td>\n",
       "      <td>16.6987</td>\n",
       "      <td>10406.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>ffb9a7b9a</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>40.3200</td>\n",
       "      <td>3187.500</td>\n",
       "      <td>41.0133</td>\n",
       "      <td>5062.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1216 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     recording_id  species_id  songtype_id  ...     f_min    t_max     f_max\n",
       "0       003bec244          14            1  ...  2531.250  45.1307   5531.25\n",
       "1       006ab765f          23            1  ...  7235.160  46.0452  11283.40\n",
       "2       007f87ba2          12            1  ...   562.500  42.2720   3281.25\n",
       "3       0099c367b          17            4  ...  1464.260  55.1996   4565.04\n",
       "4       009b760e6          10            1  ...   947.461  52.5293  10852.70\n",
       "...           ...         ...          ...  ...       ...      ...       ...\n",
       "1211    fe8d9ac40          13            1  ...    93.750  54.0960    843.75\n",
       "1212    fea6b438a           4            1  ...  2531.250  45.7653   4031.25\n",
       "1213    ff2eb9ce5           0            1  ...  5906.250  16.0213   8250.00\n",
       "1214    ffb8d8391           5            1  ...  4781.250  16.6987  10406.20\n",
       "1215    ffb9a7b9a          18            1  ...  3187.500  41.0133   5062.50\n",
       "\n",
       "[1216 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('/content/drive/MyDrive/train_tp.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1627634239232,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "gll41fyPSgLh"
   },
   "outputs": [],
   "source": [
    "# Splitting the train true positive data into train and validation\n",
    "train, validation = train_test_split(data, test_size = 0.1, stratify = data['species_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1627634241129,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "tJ5KjXwIGq_d"
   },
   "outputs": [],
   "source": [
    "def preprocess_dbscale_mel_spectrogram(file):    \n",
    "    audio = tfio.IOTensor.graph(tf.int16).from_audio(file)\n",
    "    audio_slice = audio[0:]\n",
    "\n",
    "    # remove last dimension\n",
    "    audio_tensor = tf.squeeze(audio_slice, axis=[-1])\n",
    "    audio_tensor = tf.cast(audio_tensor, tf.float32)\n",
    "\n",
    "    # Convert to spectrogram\n",
    "    spectrogram = tfio.audio.spectrogram(audio_tensor, nfft=2048, window=2048, stride=512)\n",
    "\n",
    "    # Convert to mel-spectrogram\n",
    "    mel_spectrogram = tfio.audio.melscale(spectrogram, rate=48000, mels=384, fmin=40, fmax=24000)\n",
    "\n",
    "    # Convert to db scale mel-spectrogram\n",
    "    mel_spectrogram = tfio.audio.dbscale(mel_spectrogram, top_db=80)\n",
    "\n",
    "    # Expanding the dimensions of spectrograms by 1 \n",
    "    image = tf.expand_dims(mel_spectrogram, axis= -1)\n",
    "    # Resizing the spectrogram\n",
    "    image = tf.image.resize(image, [384, 768])\n",
    "    # Converting the spectrogram to rgb\n",
    "    image = tf.image.grayscale_to_rgb(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 573,
     "status": "ok",
     "timestamp": 1627634244236,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "QK3cC2eCEjwz"
   },
   "outputs": [],
   "source": [
    "def preprocess_augment(spectrogram,label):\n",
    "    \"\"\"In this function we resize the image and perform data augumentations for train data\"\"\"\n",
    "\n",
    "    # Getting a random value and based on the random value computing the augmentation\n",
    "    a = np.random.uniform() \n",
    "    if a<0.15:\n",
    "        # Flipping the spectrogram left to right\n",
    "        spectrogram = tf.image.flip_left_right(spectrogram)\n",
    "    elif a<0.25:\n",
    "        # Flipping the spectrogram up to down\n",
    "        spectrogram = tf.image.flip_up_down(spectrogram)\n",
    "    elif a<0.5:\n",
    "        # Adding a random contrast to spectrogram\n",
    "        spectrogram = tf.image.random_contrast(spectrogram, 0.2,0.5)\n",
    "    else:\n",
    "        # Adding a random brightness to spectrogram\n",
    "        spectrogram = tf.image.random_brightness(spectrogram, 0.2)\n",
    "\n",
    "    return spectrogram, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1627634245694,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "jpMt0EmINmX5"
   },
   "outputs": [],
   "source": [
    "def preprocess_train(file):\n",
    "    #print(file)\n",
    "    #print(file['recording_id']+'.flac')\n",
    "    image = preprocess_dbscale_mel_spectrogram('/content/drive/MyDrive/'+file['recording_id']+'.flac')\n",
    "    # Computing the one hot encoded values of species_id\n",
    "    label = tf.one_hot(file['species_id'], 24)\n",
    "    # Returning the spectrogram and one hot encoded species_id\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def preprocess_val(file):\n",
    "   \n",
    "    image = preprocess_dbscale_mel_spectrogram('/content/drive/MyDrive/'+file['recording_id']+'.flac')\n",
    "\n",
    "    # Computing the one hot encoded values of species_id\n",
    "    label = tf.one_hot(file['species_id'], 24)\n",
    "    # Returning the spectrogram and one hot encoded species_id\n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 7258,
     "status": "ok",
     "timestamp": 1627634255500,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "H7udgxC2OLJi"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Creating a dataset from train data and mapping the preprocess train function \n",
    "files_ds = tf.data.Dataset.from_tensor_slices(dict(train))\n",
    "train_dataset = files_ds.map(preprocess_train).cache().map(preprocess_augment).shuffle(3).batch(8).prefetch(-1).repeat()\n",
    "\n",
    "# Creating a dataset from train data and mapping the preprocess train function \n",
    "files_ds = tf.data.Dataset.from_tensor_slices(dict(validation))\n",
    "val_dataset = files_ds.map(preprocess_val).cache().shuffle(3).batch(8).prefetch(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 645,
     "status": "ok",
     "timestamp": 1627651016413,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "LRyiVkYgONxs"
   },
   "outputs": [],
   "source": [
    "def lrap(y_true, y_pred):\n",
    "    return tf.py_function(label_ranking_average_precision_score, (y_true, y_pred), tf.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qLLKbbW0l1XB",
    "outputId": "0813f715-c157-42ea-93f2-2907ddda9fa0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.RepeatDataset"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2974,
     "status": "ok",
     "timestamp": 1627634258461,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "o0V9BkAcHhw_",
    "outputId": "b8602d15-ac34-4eac-d0bd-3b871dc69cb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "29089792/29084464 [==============================] - 0s 0us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet121 (Functional)     (None, 12, 24, 1024)      7037504   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                1560      \n",
      "=================================================================\n",
      "Total params: 7,178,776\n",
      "Trainable params: 7,095,000\n",
      "Non-trainable params: 83,776\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "backbone = tf.keras.applications.DenseNet121(include_top = False,input_shape = (384,768,3), weights=\"imagenet\")\n",
    "\n",
    "for layer in backbone.layers[:0]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "            backbone,\n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            tf.keras.layers.Dense(128, activation='relu', kernel_initializer=tf.keras.initializers.he_normal()),\n",
    "            tf.keras.layers.Dense(64, activation='relu', kernel_initializer=tf.keras.initializers.he_normal()),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dense(24,bias_initializer=tf.keras.initializers.Constant(-2.))])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 461,
     "status": "ok",
     "timestamp": 1627634262938,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "0Niy7DsfHkMP"
   },
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer=tfa.optimizers.RectifiedAdam(learning_rate=2e-3,total_steps=30*140,warmup_proportion=0.3,min_lr=1e-6), loss=tfa.losses.SigmoidFocalCrossEntropy(from_logits = True), metrics=[lrap])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2664851,
     "status": "ok",
     "timestamp": 1627641937207,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "0rX9L-UYHmAq",
    "outputId": "4a25e256-6948-40c1-eb73-d80e00eed3fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "140/140 [==============================] - 2435s 17s/step - loss: 0.6445 - lrap: 0.1566 - val_loss: 0.4716 - val_lrap: 0.1817\n",
      "\n",
      "Epoch 00001: val_lrap improved from -inf to 0.18172, saving model to /content/drive/MyDrive/model_save_densenet/weights-01-0.1817.hdf5\n",
      "Epoch 2/60\n",
      "140/140 [==============================] - 84s 602ms/step - loss: 0.5203 - lrap: 0.2098 - val_loss: 0.8092 - val_lrap: 0.1582\n",
      "\n",
      "Epoch 00002: val_lrap did not improve from 0.18172\n",
      "Epoch 3/60\n",
      "140/140 [==============================] - 86s 615ms/step - loss: 0.4761 - lrap: 0.2396 - val_loss: 3.3460 - val_lrap: 0.1859\n",
      "\n",
      "Epoch 00003: val_lrap improved from 0.18172 to 0.18588, saving model to /content/drive/MyDrive/model_save_densenet/weights-03-0.1859.hdf5\n",
      "Epoch 4/60\n",
      "140/140 [==============================] - 87s 619ms/step - loss: 0.4593 - lrap: 0.2465 - val_loss: 0.9291 - val_lrap: 0.1770\n",
      "\n",
      "Epoch 00004: val_lrap did not improve from 0.18588\n",
      "Epoch 5/60\n",
      "140/140 [==============================] - 87s 620ms/step - loss: 0.4132 - lrap: 0.3000 - val_loss: 17.4934 - val_lrap: 0.1823\n",
      "\n",
      "Epoch 00005: val_lrap did not improve from 0.18588\n",
      "Epoch 6/60\n",
      "140/140 [==============================] - 87s 619ms/step - loss: 0.4175 - lrap: 0.2886 - val_loss: 0.4130 - val_lrap: 0.2345\n",
      "\n",
      "Epoch 00006: val_lrap improved from 0.18588 to 0.23445, saving model to /content/drive/MyDrive/model_save_densenet/weights-06-0.2345.hdf5\n",
      "Epoch 7/60\n",
      "140/140 [==============================] - 87s 619ms/step - loss: 0.3816 - lrap: 0.3311 - val_loss: 0.4708 - val_lrap: 0.1988\n",
      "\n",
      "Epoch 00007: val_lrap did not improve from 0.23445\n",
      "Epoch 8/60\n",
      "140/140 [==============================] - 87s 618ms/step - loss: 0.3989 - lrap: 0.2847 - val_loss: 0.4354 - val_lrap: 0.3095\n",
      "\n",
      "Epoch 00008: val_lrap improved from 0.23445 to 0.30954, saving model to /content/drive/MyDrive/model_save_densenet/weights-08-0.3095.hdf5\n",
      "Epoch 9/60\n",
      "140/140 [==============================] - 86s 618ms/step - loss: 0.3738 - lrap: 0.3225 - val_loss: 0.4479 - val_lrap: 0.3059\n",
      "\n",
      "Epoch 00009: val_lrap did not improve from 0.30954\n",
      "Epoch 10/60\n",
      "140/140 [==============================] - 87s 620ms/step - loss: 0.3596 - lrap: 0.3449 - val_loss: 3.4536 - val_lrap: 0.2678\n",
      "\n",
      "Epoch 00010: val_lrap did not improve from 0.30954\n",
      "Epoch 11/60\n",
      "140/140 [==============================] - 87s 619ms/step - loss: 0.3501 - lrap: 0.3711 - val_loss: 0.4915 - val_lrap: 0.2310\n",
      "\n",
      "Epoch 00011: val_lrap did not improve from 0.30954\n",
      "Epoch 12/60\n",
      "140/140 [==============================] - 87s 619ms/step - loss: 0.3543 - lrap: 0.3587 - val_loss: 0.8558 - val_lrap: 0.2524\n",
      "\n",
      "Epoch 00012: val_lrap did not improve from 0.30954\n",
      "Epoch 13/60\n",
      "140/140 [==============================] - 87s 620ms/step - loss: 0.3553 - lrap: 0.3385 - val_loss: 0.3704 - val_lrap: 0.3135\n",
      "\n",
      "Epoch 00013: val_lrap improved from 0.30954 to 0.31350, saving model to /content/drive/MyDrive/model_save_densenet/weights-13-0.3135.hdf5\n",
      "Epoch 14/60\n",
      "140/140 [==============================] - 87s 619ms/step - loss: 0.3535 - lrap: 0.3541 - val_loss: 0.4026 - val_lrap: 0.3609\n",
      "\n",
      "Epoch 00014: val_lrap improved from 0.31350 to 0.36089, saving model to /content/drive/MyDrive/model_save_densenet/weights-14-0.3609.hdf5\n",
      "Epoch 15/60\n",
      "140/140 [==============================] - 87s 619ms/step - loss: 0.3433 - lrap: 0.3854 - val_loss: 0.3542 - val_lrap: 0.3380\n",
      "\n",
      "Epoch 00015: val_lrap did not improve from 0.36089\n",
      "Epoch 16/60\n",
      "140/140 [==============================] - 86s 618ms/step - loss: 0.3302 - lrap: 0.4277 - val_loss: 0.3567 - val_lrap: 0.3595\n",
      "\n",
      "Epoch 00016: val_lrap did not improve from 0.36089\n",
      "Epoch 17/60\n",
      "140/140 [==============================] - 86s 617ms/step - loss: 0.3312 - lrap: 0.4242 - val_loss: 13.4925 - val_lrap: 0.2137\n",
      "\n",
      "Epoch 00017: val_lrap did not improve from 0.36089\n",
      "Epoch 18/60\n",
      "140/140 [==============================] - 87s 618ms/step - loss: 0.3406 - lrap: 0.3873 - val_loss: 0.3603 - val_lrap: 0.3149\n",
      "\n",
      "Epoch 00018: val_lrap did not improve from 0.36089\n",
      "Epoch 19/60\n",
      "140/140 [==============================] - 86s 616ms/step - loss: 0.3299 - lrap: 0.4279 - val_loss: 0.3512 - val_lrap: 0.3287\n",
      "\n",
      "Epoch 00019: val_lrap did not improve from 0.36089\n",
      "Epoch 20/60\n",
      "140/140 [==============================] - 87s 620ms/step - loss: 0.3332 - lrap: 0.4190 - val_loss: 1.3373 - val_lrap: 0.2408\n",
      "\n",
      "Epoch 00020: val_lrap did not improve from 0.36089\n",
      "Epoch 21/60\n",
      "140/140 [==============================] - 87s 619ms/step - loss: 0.3299 - lrap: 0.4263 - val_loss: 0.3410 - val_lrap: 0.4026\n",
      "\n",
      "Epoch 00021: val_lrap improved from 0.36089 to 0.40264, saving model to /content/drive/MyDrive/model_save_densenet/weights-21-0.4026.hdf5\n",
      "Epoch 22/60\n",
      "140/140 [==============================] - 87s 620ms/step - loss: 0.3119 - lrap: 0.4845 - val_loss: 0.3228 - val_lrap: 0.4807\n",
      "\n",
      "Epoch 00022: val_lrap improved from 0.40264 to 0.48074, saving model to /content/drive/MyDrive/model_save_densenet/weights-22-0.4807.hdf5\n",
      "Epoch 23/60\n",
      "140/140 [==============================] - 87s 619ms/step - loss: 0.2982 - lrap: 0.5097 - val_loss: 0.3467 - val_lrap: 0.4009\n",
      "\n",
      "Epoch 00023: val_lrap did not improve from 0.48074\n",
      "Epoch 24/60\n",
      "140/140 [==============================] - 87s 622ms/step - loss: 0.2953 - lrap: 0.5306 - val_loss: 0.3812 - val_lrap: 0.3234\n",
      "\n",
      "Epoch 00024: val_lrap did not improve from 0.48074\n",
      "Epoch 25/60\n",
      "140/140 [==============================] - 87s 619ms/step - loss: 0.2978 - lrap: 0.5121 - val_loss: 0.3569 - val_lrap: 0.3592\n",
      "\n",
      "Epoch 00025: val_lrap did not improve from 0.48074\n",
      "Epoch 26/60\n",
      "140/140 [==============================] - 87s 619ms/step - loss: 0.2902 - lrap: 0.5489 - val_loss: 0.2853 - val_lrap: 0.5423\n",
      "\n",
      "Epoch 00026: val_lrap improved from 0.48074 to 0.54234, saving model to /content/drive/MyDrive/model_save_densenet/weights-26-0.5423.hdf5\n",
      "Epoch 27/60\n",
      "140/140 [==============================] - 86s 616ms/step - loss: 0.2814 - lrap: 0.5696 - val_loss: 0.3111 - val_lrap: 0.4465\n",
      "\n",
      "Epoch 00027: val_lrap did not improve from 0.54234\n",
      "Epoch 28/60\n",
      "140/140 [==============================] - 87s 620ms/step - loss: 0.2727 - lrap: 0.6017 - val_loss: 0.3081 - val_lrap: 0.4851\n",
      "\n",
      "Epoch 00028: val_lrap did not improve from 0.54234\n",
      "Epoch 29/60\n",
      "140/140 [==============================] - 87s 618ms/step - loss: 0.2742 - lrap: 0.5939 - val_loss: 0.2767 - val_lrap: 0.5626\n",
      "\n",
      "Epoch 00029: val_lrap improved from 0.54234 to 0.56259, saving model to /content/drive/MyDrive/model_save_densenet/weights-29-0.5626.hdf5\n",
      "Epoch 30/60\n",
      "140/140 [==============================] - 86s 618ms/step - loss: 0.2649 - lrap: 0.6140 - val_loss: 0.2660 - val_lrap: 0.6127\n",
      "\n",
      "Epoch 00030: val_lrap improved from 0.56259 to 0.61272, saving model to /content/drive/MyDrive/model_save_densenet/weights-30-0.6127.hdf5\n",
      "Epoch 31/60\n",
      "140/140 [==============================] - 87s 623ms/step - loss: 0.2615 - lrap: 0.6319 - val_loss: 0.2646 - val_lrap: 0.5979\n",
      "\n",
      "Epoch 00031: val_lrap did not improve from 0.61272\n",
      "Epoch 32/60\n",
      "140/140 [==============================] - 87s 624ms/step - loss: 0.2628 - lrap: 0.6307 - val_loss: 0.2658 - val_lrap: 0.5964\n",
      "\n",
      "Epoch 00032: val_lrap did not improve from 0.61272\n",
      "Epoch 33/60\n",
      "140/140 [==============================] - 87s 621ms/step - loss: 0.2597 - lrap: 0.6390 - val_loss: 0.2671 - val_lrap: 0.6161\n",
      "\n",
      "Epoch 00033: val_lrap improved from 0.61272 to 0.61612, saving model to /content/drive/MyDrive/model_save_densenet/weights-33-0.6161.hdf5\n",
      "Epoch 34/60\n",
      "140/140 [==============================] - 86s 616ms/step - loss: 0.2614 - lrap: 0.6283 - val_loss: 0.2674 - val_lrap: 0.6171\n",
      "\n",
      "Epoch 00034: val_lrap improved from 0.61612 to 0.61711, saving model to /content/drive/MyDrive/model_save_densenet/weights-34-0.6171.hdf5\n",
      "Epoch 35/60\n",
      "140/140 [==============================] - 87s 621ms/step - loss: 0.2599 - lrap: 0.6342 - val_loss: 0.2659 - val_lrap: 0.5984\n",
      "\n",
      "Epoch 00035: val_lrap did not improve from 0.61711\n",
      "Epoch 36/60\n",
      "140/140 [==============================] - 87s 624ms/step - loss: 0.2600 - lrap: 0.6423 - val_loss: 0.2662 - val_lrap: 0.6149\n",
      "\n",
      "Epoch 00036: val_lrap did not improve from 0.61711\n",
      "Epoch 37/60\n",
      "140/140 [==============================] - 87s 618ms/step - loss: 0.2590 - lrap: 0.6360 - val_loss: 0.2648 - val_lrap: 0.5956\n",
      "\n",
      "Epoch 00037: val_lrap did not improve from 0.61711\n",
      "Epoch 38/60\n",
      "140/140 [==============================] - 87s 623ms/step - loss: 0.2594 - lrap: 0.6395 - val_loss: 0.2650 - val_lrap: 0.5987\n",
      "\n",
      "Epoch 00038: val_lrap did not improve from 0.61711\n",
      "Epoch 39/60\n",
      "140/140 [==============================] - 87s 624ms/step - loss: 0.2638 - lrap: 0.6211 - val_loss: 0.2649 - val_lrap: 0.6096\n",
      "\n",
      "Epoch 00039: val_lrap did not improve from 0.61711\n",
      "Epoch 40/60\n",
      "140/140 [==============================] - 86s 616ms/step - loss: 0.2600 - lrap: 0.6341 - val_loss: 0.2651 - val_lrap: 0.6026\n",
      "\n",
      "Epoch 00040: val_lrap did not improve from 0.61711\n",
      "Epoch 41/60\n",
      "140/140 [==============================] - 87s 620ms/step - loss: 0.2573 - lrap: 0.6477 - val_loss: 0.2650 - val_lrap: 0.6010\n",
      "\n",
      "Epoch 00041: val_lrap did not improve from 0.61711\n",
      "Epoch 42/60\n",
      "140/140 [==============================] - 87s 621ms/step - loss: 0.2597 - lrap: 0.6355 - val_loss: 0.2668 - val_lrap: 0.6176\n",
      "\n",
      "Epoch 00042: val_lrap improved from 0.61711 to 0.61756, saving model to /content/drive/MyDrive/model_save_densenet/weights-42-0.6176.hdf5\n",
      "Epoch 43/60\n",
      "140/140 [==============================] - 87s 623ms/step - loss: 0.2591 - lrap: 0.6344 - val_loss: 0.2643 - val_lrap: 0.5983\n",
      "\n",
      "Epoch 00043: val_lrap did not improve from 0.61756\n",
      "Epoch 44/60\n",
      "140/140 [==============================] - 86s 615ms/step - loss: 0.2580 - lrap: 0.6365 - val_loss: 0.2639 - val_lrap: 0.5946\n",
      "\n",
      "Epoch 00044: val_lrap did not improve from 0.61756\n",
      "Epoch 45/60\n",
      "140/140 [==============================] - 87s 621ms/step - loss: 0.2587 - lrap: 0.6300 - val_loss: 0.2641 - val_lrap: 0.6274\n",
      "\n",
      "Epoch 00045: val_lrap improved from 0.61756 to 0.62735, saving model to /content/drive/MyDrive/model_save_densenet/weights-45-0.6274.hdf5\n",
      "Epoch 46/60\n",
      "140/140 [==============================] - 87s 622ms/step - loss: 0.2594 - lrap: 0.6405 - val_loss: 0.2641 - val_lrap: 0.6213\n",
      "\n",
      "Epoch 00046: val_lrap did not improve from 0.62735\n",
      "Epoch 47/60\n",
      "140/140 [==============================] - 86s 614ms/step - loss: 0.2601 - lrap: 0.6317 - val_loss: 0.2644 - val_lrap: 0.6112\n",
      "\n",
      "Epoch 00047: val_lrap did not improve from 0.62735\n",
      "Epoch 48/60\n",
      "140/140 [==============================] - 87s 621ms/step - loss: 0.2583 - lrap: 0.6437 - val_loss: 0.2654 - val_lrap: 0.6199\n",
      "\n",
      "Epoch 00048: val_lrap did not improve from 0.62735\n",
      "Epoch 49/60\n",
      "140/140 [==============================] - 87s 621ms/step - loss: 0.2577 - lrap: 0.6416 - val_loss: 0.2639 - val_lrap: 0.6125\n",
      "\n",
      "Epoch 00049: val_lrap did not improve from 0.62735\n",
      "Epoch 50/60\n",
      "140/140 [==============================] - 86s 618ms/step - loss: 0.2579 - lrap: 0.6417 - val_loss: 0.2641 - val_lrap: 0.6211\n",
      "\n",
      "Epoch 00050: val_lrap did not improve from 0.62735\n",
      "Epoch 51/60\n",
      "140/140 [==============================] - 87s 617ms/step - loss: 0.2570 - lrap: 0.6385 - val_loss: 0.2637 - val_lrap: 0.6099\n",
      "\n",
      "Epoch 00051: val_lrap did not improve from 0.62735\n",
      "Epoch 52/60\n",
      "140/140 [==============================] - 87s 621ms/step - loss: 0.2581 - lrap: 0.6433 - val_loss: 0.2630 - val_lrap: 0.6072\n",
      "\n",
      "Epoch 00052: val_lrap did not improve from 0.62735\n",
      "Epoch 53/60\n",
      "140/140 [==============================] - 87s 623ms/step - loss: 0.2576 - lrap: 0.6417 - val_loss: 0.2639 - val_lrap: 0.6220\n",
      "\n",
      "Epoch 00053: val_lrap did not improve from 0.62735\n",
      "Epoch 54/60\n",
      "140/140 [==============================] - 86s 615ms/step - loss: 0.2582 - lrap: 0.6447 - val_loss: 0.2635 - val_lrap: 0.6071\n",
      "\n",
      "Epoch 00054: val_lrap did not improve from 0.62735\n",
      "Epoch 55/60\n",
      "140/140 [==============================] - 87s 621ms/step - loss: 0.2548 - lrap: 0.6446 - val_loss: 0.2632 - val_lrap: 0.6086\n",
      "\n",
      "Epoch 00055: val_lrap did not improve from 0.62735\n",
      "Epoch 56/60\n",
      "140/140 [==============================] - 87s 623ms/step - loss: 0.2559 - lrap: 0.6545 - val_loss: 0.2640 - val_lrap: 0.6204\n",
      "\n",
      "Epoch 00056: val_lrap did not improve from 0.62735\n",
      "Epoch 57/60\n",
      "140/140 [==============================] - 86s 615ms/step - loss: 0.2602 - lrap: 0.6393 - val_loss: 0.2630 - val_lrap: 0.6090\n",
      "\n",
      "Epoch 00057: val_lrap did not improve from 0.62735\n",
      "Epoch 58/60\n",
      "140/140 [==============================] - 87s 624ms/step - loss: 0.2576 - lrap: 0.6509 - val_loss: 0.2652 - val_lrap: 0.6182\n",
      "\n",
      "Epoch 00058: val_lrap did not improve from 0.62735\n",
      "Epoch 59/60\n",
      "140/140 [==============================] - 87s 621ms/step - loss: 0.2560 - lrap: 0.6555 - val_loss: 0.2643 - val_lrap: 0.6187\n",
      "\n",
      "Epoch 00059: val_lrap did not improve from 0.62735\n",
      "Epoch 60/60\n",
      "140/140 [==============================] - 87s 622ms/step - loss: 0.2577 - lrap: 0.6444 - val_loss: 0.2636 - val_lrap: 0.6240\n",
      "\n",
      "Epoch 00060: val_lrap did not improve from 0.62735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4cf209afd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset,steps_per_epoch=140, validation_data=val_dataset,epochs = 60,callbacks=callback_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2662227,
     "status": "ok",
     "timestamp": 1627649319121,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "mbSn-E1aJWIb",
    "outputId": "7319c58a-8884-4789-81fb-010fa3dc46c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "140/140 [==============================] - 91s 646ms/step - loss: 0.2553 - lrap: 0.6547 - val_loss: 0.2635 - val_lrap: 0.6164\n",
      "\n",
      "Epoch 00001: val_lrap did not improve from 0.62735\n",
      "Epoch 2/60\n",
      "140/140 [==============================] - 86s 614ms/step - loss: 0.2544 - lrap: 0.6527 - val_loss: 0.2621 - val_lrap: 0.6170\n",
      "\n",
      "Epoch 00002: val_lrap did not improve from 0.62735\n",
      "Epoch 3/60\n",
      "140/140 [==============================] - 86s 617ms/step - loss: 0.2565 - lrap: 0.6468 - val_loss: 0.2626 - val_lrap: 0.6118\n",
      "\n",
      "Epoch 00003: val_lrap did not improve from 0.62735\n",
      "Epoch 4/60\n",
      "140/140 [==============================] - 86s 616ms/step - loss: 0.2576 - lrap: 0.6400 - val_loss: 0.2629 - val_lrap: 0.6274\n",
      "\n",
      "Epoch 00004: val_lrap improved from 0.62735 to 0.62739, saving model to /content/drive/MyDrive/model_save_densenet/weights-04-0.6274.hdf5\n",
      "Epoch 5/60\n",
      "140/140 [==============================] - 86s 617ms/step - loss: 0.2585 - lrap: 0.6395 - val_loss: 0.2625 - val_lrap: 0.6087\n",
      "\n",
      "Epoch 00005: val_lrap did not improve from 0.62739\n",
      "Epoch 6/60\n",
      "140/140 [==============================] - 86s 616ms/step - loss: 0.2555 - lrap: 0.6625 - val_loss: 0.2626 - val_lrap: 0.6128\n",
      "\n",
      "Epoch 00006: val_lrap did not improve from 0.62739\n",
      "Epoch 7/60\n",
      "140/140 [==============================] - 86s 618ms/step - loss: 0.2581 - lrap: 0.6431 - val_loss: 0.2618 - val_lrap: 0.6104\n",
      "\n",
      "Epoch 00007: val_lrap did not improve from 0.62739\n",
      "Epoch 8/60\n",
      "140/140 [==============================] - 86s 617ms/step - loss: 0.2556 - lrap: 0.6461 - val_loss: 0.2619 - val_lrap: 0.6334\n",
      "\n",
      "Epoch 00008: val_lrap improved from 0.62739 to 0.63344, saving model to /content/drive/MyDrive/model_save_densenet/weights-08-0.6334.hdf5\n",
      "Epoch 9/60\n",
      "140/140 [==============================] - 87s 618ms/step - loss: 0.2538 - lrap: 0.6548 - val_loss: 0.2622 - val_lrap: 0.6256\n",
      "\n",
      "Epoch 00009: val_lrap did not improve from 0.63344\n",
      "Epoch 10/60\n",
      "140/140 [==============================] - 87s 618ms/step - loss: 0.2567 - lrap: 0.6430 - val_loss: 0.2604 - val_lrap: 0.6106\n",
      "\n",
      "Epoch 00010: val_lrap did not improve from 0.63344\n",
      "Epoch 11/60\n",
      "140/140 [==============================] - 88s 626ms/step - loss: 0.2530 - lrap: 0.6628 - val_loss: 0.2611 - val_lrap: 0.6112\n",
      "\n",
      "Epoch 00011: val_lrap did not improve from 0.63344\n",
      "Epoch 12/60\n",
      "140/140 [==============================] - 87s 619ms/step - loss: 0.2563 - lrap: 0.6454 - val_loss: 0.2623 - val_lrap: 0.6153\n",
      "\n",
      "Epoch 00012: val_lrap did not improve from 0.63344\n",
      "Epoch 13/60\n",
      "140/140 [==============================] - 86s 616ms/step - loss: 0.2526 - lrap: 0.6678 - val_loss: 0.2618 - val_lrap: 0.6257\n",
      "\n",
      "Epoch 00013: val_lrap did not improve from 0.63344\n",
      "Epoch 14/60\n",
      "140/140 [==============================] - 86s 617ms/step - loss: 0.2530 - lrap: 0.6514 - val_loss: 0.2632 - val_lrap: 0.6252\n",
      "\n",
      "Epoch 00014: val_lrap did not improve from 0.63344\n",
      "Epoch 15/60\n",
      "140/140 [==============================] - 86s 616ms/step - loss: 0.2532 - lrap: 0.6574 - val_loss: 0.2628 - val_lrap: 0.6167\n",
      "\n",
      "Epoch 00015: val_lrap did not improve from 0.63344\n",
      "Epoch 16/60\n",
      "140/140 [==============================] - 86s 618ms/step - loss: 0.2553 - lrap: 0.6538 - val_loss: 0.2617 - val_lrap: 0.6117\n",
      "\n",
      "Epoch 00016: val_lrap did not improve from 0.63344\n",
      "Epoch 17/60\n",
      "140/140 [==============================] - 86s 618ms/step - loss: 0.2544 - lrap: 0.6498 - val_loss: 0.2608 - val_lrap: 0.6132\n",
      "\n",
      "Epoch 00017: val_lrap did not improve from 0.63344\n",
      "Epoch 18/60\n",
      "140/140 [==============================] - 86s 616ms/step - loss: 0.2525 - lrap: 0.6615 - val_loss: 0.2624 - val_lrap: 0.6326\n",
      "\n",
      "Epoch 00018: val_lrap did not improve from 0.63344\n",
      "Epoch 19/60\n",
      "140/140 [==============================] - 86s 617ms/step - loss: 0.2539 - lrap: 0.6508 - val_loss: 0.2610 - val_lrap: 0.6047\n",
      "\n",
      "Epoch 00019: val_lrap did not improve from 0.63344\n",
      "Epoch 20/60\n",
      "140/140 [==============================] - 86s 616ms/step - loss: 0.2531 - lrap: 0.6582 - val_loss: 0.2625 - val_lrap: 0.6267\n",
      "\n",
      "Epoch 00020: val_lrap did not improve from 0.63344\n",
      "Epoch 21/60\n",
      "140/140 [==============================] - 86s 617ms/step - loss: 0.2535 - lrap: 0.6562 - val_loss: 0.2624 - val_lrap: 0.6018\n",
      "\n",
      "Epoch 00021: val_lrap did not improve from 0.63344\n",
      "Epoch 22/60\n",
      "140/140 [==============================] - 86s 617ms/step - loss: 0.2541 - lrap: 0.6506 - val_loss: 0.2615 - val_lrap: 0.5958\n",
      "\n",
      "Epoch 00022: val_lrap did not improve from 0.63344\n",
      "Epoch 23/60\n",
      "140/140 [==============================] - 86s 616ms/step - loss: 0.2550 - lrap: 0.6523 - val_loss: 0.2611 - val_lrap: 0.6204\n",
      "\n",
      "Epoch 00023: val_lrap did not improve from 0.63344\n",
      "Epoch 24/60\n",
      "140/140 [==============================] - 86s 614ms/step - loss: 0.2555 - lrap: 0.6509 - val_loss: 0.2617 - val_lrap: 0.6106\n",
      "\n",
      "Epoch 00024: val_lrap did not improve from 0.63344\n",
      "Epoch 25/60\n",
      "140/140 [==============================] - 86s 616ms/step - loss: 0.2540 - lrap: 0.6598 - val_loss: 0.2605 - val_lrap: 0.6067\n",
      "\n",
      "Epoch 00025: val_lrap did not improve from 0.63344\n",
      "Epoch 26/60\n",
      "140/140 [==============================] - 86s 615ms/step - loss: 0.2521 - lrap: 0.6575 - val_loss: 0.2618 - val_lrap: 0.6249\n",
      "\n",
      "Epoch 00026: val_lrap did not improve from 0.63344\n",
      "Epoch 27/60\n",
      "140/140 [==============================] - 87s 621ms/step - loss: 0.2525 - lrap: 0.6545 - val_loss: 0.2597 - val_lrap: 0.6054\n",
      "\n",
      "Epoch 00027: val_lrap did not improve from 0.63344\n",
      "Epoch 28/60\n",
      "140/140 [==============================] - 87s 620ms/step - loss: 0.2528 - lrap: 0.6539 - val_loss: 0.2599 - val_lrap: 0.6181\n",
      "\n",
      "Epoch 00028: val_lrap did not improve from 0.63344\n",
      "Epoch 29/60\n",
      "140/140 [==============================] - 87s 619ms/step - loss: 0.2526 - lrap: 0.6571 - val_loss: 0.2602 - val_lrap: 0.6181\n",
      "\n",
      "Epoch 00029: val_lrap did not improve from 0.63344\n",
      "Epoch 30/60\n",
      "140/140 [==============================] - 86s 617ms/step - loss: 0.2515 - lrap: 0.6655 - val_loss: 0.2601 - val_lrap: 0.6365\n",
      "\n",
      "Epoch 00030: val_lrap improved from 0.63344 to 0.63646, saving model to /content/drive/MyDrive/model_save_densenet/weights-30-0.6365.hdf5\n",
      "Epoch 31/60\n",
      "140/140 [==============================] - 87s 620ms/step - loss: 0.2511 - lrap: 0.6627 - val_loss: 0.2606 - val_lrap: 0.6276\n",
      "\n",
      "Epoch 00031: val_lrap did not improve from 0.63646\n",
      "Epoch 32/60\n",
      "140/140 [==============================] - 87s 618ms/step - loss: 0.2526 - lrap: 0.6630 - val_loss: 0.2602 - val_lrap: 0.6279\n",
      "\n",
      "Epoch 00032: val_lrap did not improve from 0.63646\n",
      "Epoch 33/60\n",
      "140/140 [==============================] - 86s 618ms/step - loss: 0.2540 - lrap: 0.6517 - val_loss: 0.2603 - val_lrap: 0.6107\n",
      "\n",
      "Epoch 00033: val_lrap did not improve from 0.63646\n",
      "Epoch 34/60\n",
      "140/140 [==============================] - 86s 616ms/step - loss: 0.2522 - lrap: 0.6649 - val_loss: 0.2612 - val_lrap: 0.6126\n",
      "\n",
      "Epoch 00034: val_lrap did not improve from 0.63646\n",
      "Epoch 35/60\n",
      "140/140 [==============================] - 86s 618ms/step - loss: 0.2536 - lrap: 0.6610 - val_loss: 0.2597 - val_lrap: 0.6070\n",
      "\n",
      "Epoch 00035: val_lrap did not improve from 0.63646\n",
      "Epoch 36/60\n",
      "140/140 [==============================] - 87s 619ms/step - loss: 0.2525 - lrap: 0.6605 - val_loss: 0.2603 - val_lrap: 0.6221\n",
      "\n",
      "Epoch 00036: val_lrap did not improve from 0.63646\n",
      "Epoch 37/60\n",
      "140/140 [==============================] - 86s 617ms/step - loss: 0.2526 - lrap: 0.6568 - val_loss: 0.2606 - val_lrap: 0.6251\n",
      "\n",
      "Epoch 00037: val_lrap did not improve from 0.63646\n",
      "Epoch 38/60\n",
      "140/140 [==============================] - 86s 618ms/step - loss: 0.2499 - lrap: 0.6738 - val_loss: 0.2605 - val_lrap: 0.6313\n",
      "\n",
      "Epoch 00038: val_lrap did not improve from 0.63646\n",
      "Epoch 39/60\n",
      "140/140 [==============================] - 86s 616ms/step - loss: 0.2537 - lrap: 0.6632 - val_loss: 0.2603 - val_lrap: 0.6331\n",
      "\n",
      "Epoch 00039: val_lrap did not improve from 0.63646\n",
      "Epoch 40/60\n",
      "140/140 [==============================] - 87s 619ms/step - loss: 0.2526 - lrap: 0.6694 - val_loss: 0.2610 - val_lrap: 0.6283\n",
      "\n",
      "Epoch 00040: val_lrap did not improve from 0.63646\n",
      "Epoch 41/60\n",
      "140/140 [==============================] - 87s 618ms/step - loss: 0.2505 - lrap: 0.6683 - val_loss: 0.2606 - val_lrap: 0.6449\n",
      "\n",
      "Epoch 00041: val_lrap improved from 0.63646 to 0.64487, saving model to /content/drive/MyDrive/model_save_densenet/weights-41-0.6449.hdf5\n",
      "Epoch 42/60\n",
      "140/140 [==============================] - 87s 620ms/step - loss: 0.2547 - lrap: 0.6508 - val_loss: 0.2602 - val_lrap: 0.6281\n",
      "\n",
      "Epoch 00042: val_lrap did not improve from 0.64487\n",
      "Epoch 43/60\n",
      "140/140 [==============================] - 87s 619ms/step - loss: 0.2482 - lrap: 0.6699 - val_loss: 0.2612 - val_lrap: 0.6288\n",
      "\n",
      "Epoch 00043: val_lrap did not improve from 0.64487\n",
      "Epoch 44/60\n",
      "140/140 [==============================] - 87s 621ms/step - loss: 0.2486 - lrap: 0.6707 - val_loss: 0.2599 - val_lrap: 0.6141\n",
      "\n",
      "Epoch 00044: val_lrap did not improve from 0.64487\n",
      "Epoch 45/60\n",
      "140/140 [==============================] - 86s 617ms/step - loss: 0.2496 - lrap: 0.6736 - val_loss: 0.2595 - val_lrap: 0.6102\n",
      "\n",
      "Epoch 00045: val_lrap did not improve from 0.64487\n",
      "Epoch 46/60\n",
      "140/140 [==============================] - 86s 617ms/step - loss: 0.2497 - lrap: 0.6609 - val_loss: 0.2612 - val_lrap: 0.6113\n",
      "\n",
      "Epoch 00046: val_lrap did not improve from 0.64487\n",
      "Epoch 47/60\n",
      "140/140 [==============================] - 87s 619ms/step - loss: 0.2492 - lrap: 0.6732 - val_loss: 0.2612 - val_lrap: 0.6098\n",
      "\n",
      "Epoch 00047: val_lrap did not improve from 0.64487\n",
      "Epoch 48/60\n",
      "140/140 [==============================] - 87s 619ms/step - loss: 0.2538 - lrap: 0.6548 - val_loss: 0.2612 - val_lrap: 0.6222\n",
      "\n",
      "Epoch 00048: val_lrap did not improve from 0.64487\n",
      "Epoch 49/60\n",
      "140/140 [==============================] - 87s 620ms/step - loss: 0.2480 - lrap: 0.6766 - val_loss: 0.2601 - val_lrap: 0.6402\n",
      "\n",
      "Epoch 00049: val_lrap did not improve from 0.64487\n",
      "Epoch 50/60\n",
      "140/140 [==============================] - 87s 619ms/step - loss: 0.2488 - lrap: 0.6689 - val_loss: 0.2592 - val_lrap: 0.6067\n",
      "\n",
      "Epoch 00050: val_lrap did not improve from 0.64487\n",
      "Epoch 51/60\n",
      "140/140 [==============================] - 87s 620ms/step - loss: 0.2521 - lrap: 0.6723 - val_loss: 0.2603 - val_lrap: 0.6287\n",
      "\n",
      "Epoch 00051: val_lrap did not improve from 0.64487\n",
      "Epoch 52/60\n",
      "140/140 [==============================] - 87s 620ms/step - loss: 0.2498 - lrap: 0.6642 - val_loss: 0.2602 - val_lrap: 0.6394\n",
      "\n",
      "Epoch 00052: val_lrap did not improve from 0.64487\n",
      "Epoch 53/60\n",
      "140/140 [==============================] - 87s 620ms/step - loss: 0.2495 - lrap: 0.6759 - val_loss: 0.2593 - val_lrap: 0.6201\n",
      "\n",
      "Epoch 00053: val_lrap did not improve from 0.64487\n",
      "Epoch 54/60\n",
      "140/140 [==============================] - 86s 618ms/step - loss: 0.2484 - lrap: 0.6690 - val_loss: 0.2625 - val_lrap: 0.6404\n",
      "\n",
      "Epoch 00054: val_lrap did not improve from 0.64487\n",
      "Epoch 55/60\n",
      "140/140 [==============================] - 86s 616ms/step - loss: 0.2483 - lrap: 0.6742 - val_loss: 0.2605 - val_lrap: 0.6292\n",
      "\n",
      "Epoch 00055: val_lrap did not improve from 0.64487\n",
      "Epoch 56/60\n",
      "140/140 [==============================] - 86s 618ms/step - loss: 0.2502 - lrap: 0.6720 - val_loss: 0.2590 - val_lrap: 0.6104\n",
      "\n",
      "Epoch 00056: val_lrap did not improve from 0.64487\n",
      "Epoch 57/60\n",
      "140/140 [==============================] - 86s 616ms/step - loss: 0.2480 - lrap: 0.6707 - val_loss: 0.2599 - val_lrap: 0.6163\n",
      "\n",
      "Epoch 00057: val_lrap did not improve from 0.64487\n",
      "Epoch 58/60\n",
      "140/140 [==============================] - 87s 618ms/step - loss: 0.2517 - lrap: 0.6665 - val_loss: 0.2601 - val_lrap: 0.6170\n",
      "\n",
      "Epoch 00058: val_lrap did not improve from 0.64487\n",
      "Epoch 59/60\n",
      "140/140 [==============================] - 87s 621ms/step - loss: 0.2478 - lrap: 0.6735 - val_loss: 0.2612 - val_lrap: 0.6129\n",
      "\n",
      "Epoch 00059: val_lrap did not improve from 0.64487\n",
      "Epoch 60/60\n",
      "140/140 [==============================] - 87s 619ms/step - loss: 0.2503 - lrap: 0.6637 - val_loss: 0.2608 - val_lrap: 0.6266\n",
      "\n",
      "Epoch 00060: val_lrap did not improve from 0.64487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4cc8136e50>"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset,steps_per_epoch=140, validation_data=val_dataset,epochs = 60,callbacks=callback_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 3784,
     "status": "ok",
     "timestamp": 1627651167568,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "aP91c_PEUfJt"
   },
   "outputs": [],
   "source": [
    "!pip install --quiet efficientnet\n",
    "import efficientnet.tfkeras as efn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 490,
     "status": "ok",
     "timestamp": 1627634274825,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "qQigeA_bDNSH",
    "outputId": "75406cde-de43-45b1-a589-01fda463dc8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "tf.keras.backend.clear_session()\n",
    "%load_ext tensorboard\n",
    "log_dir=os.path.join(\"/content/drive/MyDrive/logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True,write_grads=True)\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(monitor='val_accuracy', patience=2, verbose=1)\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "filepath=\"/content/drive/MyDrive/model_save_densenet/weights-{epoch:02d}-{val_lrap:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_lrap',  verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callback_list = [checkpoint,tensorboard_callback]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3813,
     "status": "ok",
     "timestamp": 1627426142147,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "C9X7CIX3Uk2H",
    "outputId": "1f088843-8755-4f6c-cc09-7e61d1ea7911"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b3_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
      "44113920/44107200 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "inputs =Input(shape=(384,768,3))\n",
    "base_model = efn.EfficientNetB3(input_tensor=inputs,include_top=False,weights='imagenet')\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x =Dropout(.5)(x)\n",
    "x=tf.keras.layers.Dense(60, activation='relu', kernel_initializer=tf.keras.initializers.he_normal())(x)\n",
    "x =Dropout(.6)(x)\n",
    "output =Dense(24,bias_initializer=tf.keras.initializers.Constant(-2.))(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "model.compile(optimizer=tfa.optimizers.RectifiedAdam(learning_rate=2e-3,total_steps=30*140,warmup_proportion=0.3,min_lr=1e-6), loss=tfa.losses.SigmoidFocalCrossEntropy(from_logits = True), metrics=[lrap])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Qaw2n_8Xwqq",
    "outputId": "5ed295c6-d881-4e50-b919-d9a692eea9ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      " 13/140 [=>............................] - ETA: 1:02:43 - loss: 0.4956 - lrap: 0.1496"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset,steps_per_epoch=140, validation_data=val_dataset,epochs =35,callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zqdVaSZC_zhI"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 4380,
     "status": "ok",
     "timestamp": 1627651131415,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "bjtDombDi78b"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow_addons.optimizers import RectifiedAdam\n",
    "tf.keras.optimizers.RectifiedAdam = RectifiedAdam\n",
    "\n",
    "\n",
    "model_densenet = tf.keras.models.load_model('/content/drive/MyDrive/model_save_densenet/weights-41-0.6449.hdf5', custom_objects = {'RectifiedAdam' : RectifiedAdam,'score':lrap},compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 4393,
     "status": "ok",
     "timestamp": 1627651178528,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "ih4GlQp5vOd_"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow_addons.optimizers import RectifiedAdam\n",
    "tf.keras.optimizers.RectifiedAdam = RectifiedAdam\n",
    "\n",
    "\n",
    "model_efficientnet = tf.keras.models.load_model('/content/drive/MyDrive/model_save/weights-29-0.7197.hdf5', custom_objects = {'RectifiedAdam' : RectifiedAdam,'score':lrap},compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 610,
     "status": "ok",
     "timestamp": 1627651199741,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "iseLCh3V5nPk"
   },
   "outputs": [],
   "source": [
    "model_densenet.compile(optimizer=tfa.optimizers.RectifiedAdam(learning_rate=2e-3,total_steps=30*140,warmup_proportion=0.3,min_lr=1e-6), loss=tfa.losses.SigmoidFocalCrossEntropy(from_logits = True), metrics=[lrap])\n",
    "model_efficientnet.compile(optimizer=tfa.optimizers.RectifiedAdam(learning_rate=2e-3,total_steps=30*140,warmup_proportion=0.3,min_lr=1e-6), loss=tfa.losses.SigmoidFocalCrossEntropy(from_logits = True), metrics=[lrap])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21185,
     "status": "ok",
     "timestamp": 1627472049057,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "2C32-McS6KlG",
    "outputId": "0cfdcf65-e9c7-4fec-e2c8-a2d53556d0d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 384, 768, 3)\n",
      "(8, 24)\n"
     ]
    }
   ],
   "source": [
    "for i in val_dataset:\n",
    "  #print(i[0][0].shape)\n",
    "  val_data=i[0]\n",
    "  val_tar=i[1]\n",
    "  print(val_data.shape)\n",
    "  print(val_tar.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 443,
     "status": "ok",
     "timestamp": 1627472053362,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "E_PadyzJNvMh",
    "outputId": "1818e0df-3496-4b58-a24f-c538a7dd0d0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth=val_tar.numpy()\n",
    "truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7398,
     "status": "ok",
     "timestamp": 1627472065596,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "N9po-3iNNJR_",
    "outputId": "bb07aefc-ee16-43b1-9f3d-b08a6064bc7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.2465618 , -3.3943036 , -4.3925257 , -2.290316  , -1.7539396 ,\n",
       "        -3.5315552 , -4.4996414 , -3.8752434 , -0.484401  , -3.2973223 ,\n",
       "        -2.753775  , -4.504846  , -3.8070035 , -2.3921313 , -1.9515926 ,\n",
       "        -3.7625332 , -4.0075183 , -4.2396836 , -2.2933877 , -4.115899  ,\n",
       "        -4.1744514 , -0.50506294, -2.3186665 , -3.210285  ],\n",
       "       [-2.742435  , -3.34042   , -2.86093   , -1.7298416 , -2.9020803 ,\n",
       "        -1.8732426 , -0.95581657, -2.0135436 , -3.0257254 , -1.6178907 ,\n",
       "        -1.7288537 , -1.2508895 , -3.0720544 , -3.9870288 , -2.9663024 ,\n",
       "        -2.1763926 , -3.3161416 , -1.57058   , -3.0576782 , -1.3970466 ,\n",
       "        -1.7404428 , -3.25169   , -1.6373502 , -1.7492464 ],\n",
       "       [-3.4290519 , -4.4029293 , -3.3085802 , -1.7742989 , -3.3606858 ,\n",
       "        -2.096531  , -0.2673533 , -2.4322078 , -3.5526164 , -1.5294093 ,\n",
       "        -1.9050455 , -1.1807325 , -3.46665   , -4.979808  , -3.5122013 ,\n",
       "        -1.9108572 , -3.7977736 , -1.5024478 , -3.5247307 , -1.1565347 ,\n",
       "        -2.1067932 , -3.8123856 , -1.8314507 , -1.7191975 ],\n",
       "       [-3.3859367 , -3.9770765 , -3.4402814 , -2.114396  , -3.568463  ,\n",
       "        -1.7951444 , -0.47747445, -3.2704048 , -4.3287287 , -2.1749175 ,\n",
       "        -2.577284  , -2.7679026 , -2.6090355 , -4.8103886 , -4.173088  ,\n",
       "        -1.4004626 , -3.359901  , -2.884162  , -3.866376  ,  0.53548074,\n",
       "        -2.9184294 , -4.681925  , -1.6475034 , -3.273662  ],\n",
       "       [-5.079856  , -5.2013593 , -4.1815557 , -2.72333   , -4.7674313 ,\n",
       "        -2.9518166 , -2.5827632 , -2.644701  , -3.735678  , -2.3001356 ,\n",
       "        -3.7712188 , -3.0223289 , -4.0778503 , -5.8068705 , -3.988659  ,\n",
       "        -3.7463408 , -3.9860253 , -3.7854676 , -5.1726875 , -3.3543622 ,\n",
       "        -3.7427664 , -4.6450405 , -1.7829821 ,  2.0061903 ],\n",
       "       [-2.3448842 , -4.203064  , -3.0650978 , -1.3217843 , -2.6650493 ,\n",
       "         0.07605362, -2.2850738 , -3.0146964 , -3.2040954 , -2.1685455 ,\n",
       "        -1.7834469 , -2.2032444 , -2.9835374 , -3.6252418 , -3.4119453 ,\n",
       "        -3.4871283 , -4.392937  , -2.5683017 , -3.0912042 , -1.2403905 ,\n",
       "        -2.6225255 , -3.9968338 , -1.7563617 , -2.5029705 ],\n",
       "       [-5.668714  , -5.635807  , -4.614422  , -2.908454  , -4.8589687 ,\n",
       "        -3.2537403 , -2.9472113 , -3.0600681 , -3.9183247 , -2.317466  ,\n",
       "        -4.3958497 , -3.529272  , -4.174657  , -5.9904027 , -4.229407  ,\n",
       "        -4.260895  , -4.1631703 , -4.1154394 , -5.397718  , -3.6350553 ,\n",
       "        -4.00619   , -4.760866  , -2.0028627 ,  2.459578  ],\n",
       "       [-3.9816575 , -2.9030628 , -3.701037  , -2.1063225 , -4.9741945 ,\n",
       "        -3.1895921 , -2.5786576 , -0.5990547 , -5.0150785 , -2.7049246 ,\n",
       "        -2.9793363 , -1.9929161 , -4.4628453 , -5.0044227 , -2.418902  ,\n",
       "         0.51086533, -3.1474733 , -2.5079663 , -4.921567  , -2.1852355 ,\n",
       "        -2.6266174 , -6.007029  , -1.9901862 , -2.1411295 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.predict(val_data)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mc-6P5sN5lAN"
   },
   "outputs": [],
   "source": [
    "def _one_sample_positive_class_precisions(scores, truth):\n",
    "    \"\"\"Calculate precisions for each true class for a single sample.\n",
    "\n",
    "    Args:\n",
    "      scores: np.array of (num_classes,) giving the individual classifier scores.\n",
    "      truth: np.array of (num_classes,) bools indicating which classes are true.\n",
    "\n",
    "    Returns:\n",
    "      pos_class_indices: np.array of indices of the true classes for this sample.\n",
    "      pos_class_precisions: np.array of precisions corresponding to each of those\n",
    "        classes.\n",
    "    \"\"\"\n",
    "    num_classes = scores.shape[0]\n",
    "    pos_class_indices = np.flatnonzero(truth > 0)\n",
    "    # Only calculate precisions if there are some true classes.\n",
    "    if not len(pos_class_indices):\n",
    "        return pos_class_indices, np.zeros(0)\n",
    "    # Retrieval list of classes for this sample.\n",
    "    retrieved_classes = np.argsort(scores)[::-1]\n",
    "    # class_rankings[top_scoring_class_index] == 0 etc.\n",
    "    class_rankings = np.zeros(num_classes, dtype=np.int)\n",
    "    class_rankings[retrieved_classes] = range(num_classes)\n",
    "    # Which of these is a true label?\n",
    "    retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n",
    "    retrieved_class_true[class_rankings[pos_class_indices]] = True\n",
    "    # Num hits for every truncated retrieval list.\n",
    "    retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n",
    "    # Precision of retrieval list truncated at each hit, in order of pos_labels.\n",
    "    precision_at_hits = (\n",
    "            retrieved_cumulative_hits[class_rankings[pos_class_indices]] /\n",
    "            (1 + class_rankings[pos_class_indices].astype(np.float)))\n",
    "    return pos_class_indices, precision_at_hits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yTLNyF9I4fw3"
   },
   "outputs": [],
   "source": [
    "def calculate_per_class_lwlrap(truth, scores):\n",
    "    \"\"\"Calculate label-weighted label-ranking average precision.\n",
    "\n",
    "    Arguments:\n",
    "      truth: np.array of (num_samples, num_classes) giving boolean ground-truth\n",
    "        of presence of that class in that sample.\n",
    "      scores: np.array of (num_samples, num_classes) giving the classifier-under-\n",
    "        test's real-valued score for each class for each sample.\n",
    "\n",
    "    Returns:\n",
    "      per_class_lwlrap: np.array of (num_classes,) giving the lwlrap for each\n",
    "        class.\n",
    "      weight_per_class: np.array of (num_classes,) giving the prior of each\n",
    "        class within the truth labels.  Then the overall unbalanced lwlrap is\n",
    "        simply np.sum(per_class_lwlrap * weight_per_class)\n",
    "    \"\"\"\n",
    "    assert truth.shape == scores.shape\n",
    "    num_samples, num_classes = scores.shape\n",
    "    # Space to store a distinct precision value for each class on each sample.\n",
    "    # Only the classes that are true for each sample will be filled in.\n",
    "    precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n",
    "    for sample_num in range(num_samples):\n",
    "        pos_class_indices, precision_at_hits = (\n",
    "            _one_sample_positive_class_precisions(scores[sample_num, :],\n",
    "                                                  truth[sample_num, :]))\n",
    "        precisions_for_samples_by_classes[sample_num, pos_class_indices] = (\n",
    "            precision_at_hits)\n",
    "    labels_per_class = np.sum(truth > 0, axis=0)\n",
    "    weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n",
    "    # Form average of each column, i.e. all the precisions assigned to labels in\n",
    "    # a particular class.\n",
    "    per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) /\n",
    "                        np.maximum(1, labels_per_class))\n",
    "    # overall_lwlrap = simple average of all the actual per-class, per-sample precisions\n",
    "    #                = np.sum(precisions_for_samples_by_classes) / np.sum(precisions_for_samples_by_classes > 0)\n",
    "    #           also = weighted mean of per-class lwlraps, weighted by class label prior across samples\n",
    "    #                = np.sum(per_class_lwlrap * weight_per_class)\n",
    "    return per_class_lwlrap, weight_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1627472201923,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "xV-_nTpNNEFi",
    "outputId": "1f3cc29a-54f0-4bb8-8174-a468fc67ffaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each class score [0.    0.    0.    0.125 0.    1.    1.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    1.    0.    0.    0.    1.    0.    0.5   0.    1.   ]\n",
      "Weight of each class [0.    0.    0.    0.125 0.    0.125 0.125 0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.125 0.    0.    0.    0.125 0.    0.125 0.    0.25 ]\n",
      "LwLRAP 0.828125\n"
     ]
    }
   ],
   "source": [
    "#https://www.kaggle.com/pkmahan/understanding-lwlrap\n",
    "score, weight = calculate_per_class_lwlrap(truth, scores)\n",
    "print(\"Each class score\", score)\n",
    "print(\"Weight of each class\", weight)\n",
    "LwLRAP = (score*weight).sum()\n",
    "print(\"LwLRAP\", LwLRAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3751,
     "status": "ok",
     "timestamp": 1627214889038,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "_zDQHpHd66Mw",
    "outputId": "adbfc4f0-dc3f-43a5-9b07-3e252f0787fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.8795855  -1.009711   -2.0507715  -1.5180122  -1.4193183  -3.3795724\n",
      "  -3.9589534  -2.8786724  -1.982974   -2.4006782  -3.4823356  -3.7908354\n",
      "  -2.2965028  -1.1996514  -0.9100561  -2.5173197  -2.2900631  -3.7691789\n",
      "  -1.5678018  -3.8859668  -3.3389845  -1.4357482  -2.7254927  -3.0755315 ]\n",
      " [-2.9020448  -1.7371556  -2.695209   -1.6467334  -3.7665436  -2.5067384\n",
      "  -2.5388937  -1.5765082  -3.9240503  -2.030638   -2.6647189  -2.2745652\n",
      "  -3.3041015  -3.1240602  -2.4682295  -2.8397055   0.61313987 -1.8521237\n",
      "  -3.6162276  -3.0191774  -2.4631832  -3.364745   -2.8097148  -2.598744  ]\n",
      " [-4.576619   -5.372407   -4.0699077  -2.70264    -4.406909   -2.163323\n",
      "  -3.6652675  -4.159107   -3.7323215  -2.5138373  -2.7592382  -3.2446318\n",
      "  -3.2720413  -6.333077   -5.15286    -4.5315127  -5.4712048  -3.385694\n",
      "  -4.8542557  -4.2132144  -3.7901258  -5.9710517  -2.363399    3.0014954 ]\n",
      " [-1.471442   -1.6796668  -1.7189535  -1.3481913  -2.0203722  -1.5097107\n",
      "  -2.248396   -2.1254756  -2.041546   -2.0744607  -2.2792335  -2.4322972\n",
      "  -1.2998583  -2.0689542  -2.0113606  -2.055171   -2.0467663  -2.2932153\n",
      "  -1.4272832  -2.2169452  -2.4704695  -2.5228217  -1.604405   -1.6575236 ]\n",
      " [-4.1133904  -4.471692   -3.5464773  -2.4533992  -3.7391534  -1.9409897\n",
      "  -3.1611166  -3.450201   -3.2840257  -2.3315544  -2.4672523  -2.9247475\n",
      "  -3.1037185  -5.1951594  -4.1815033  -3.7558465  -4.9065056  -3.247979\n",
      "  -4.4009886  -3.8244405  -3.4407053  -5.06404    -2.0393767   1.9441576 ]\n",
      " [-1.3718485  -1.4672511  -2.343013   -1.4351945  -1.3346896  -2.433556\n",
      "  -3.3914115  -3.053143   -1.5322187  -2.4901485  -3.3584785  -3.4369757\n",
      "  -1.3015265  -1.4916232  -1.6332293  -2.6736655  -2.2845268  -3.0479193\n",
      "  -1.2064176  -3.0127215  -3.1183472  -1.8352177  -2.4320102  -2.7685974 ]\n",
      " [-1.6149246  -2.2850351   1.0488535  -1.5811032  -2.3834577  -3.1074533\n",
      "  -3.3643665  -2.7338676  -3.0398612  -3.0632343  -2.5293255  -3.2603898\n",
      "  -1.741354   -2.6355019  -3.2462406  -3.691605   -2.4167063  -3.0882745\n",
      "  -2.3136845  -3.3450856  -3.730267   -3.0621119  -2.1323435  -2.310615  ]\n",
      " [-2.7858434  -2.2992697  -2.1641958  -1.6516442  -2.691268   -1.9013302\n",
      "  -1.4287665  -1.3705127  -3.1020985  -1.7243315  -1.632214   -1.5400052\n",
      "  -2.742875   -2.5226808  -1.8068576  -1.317939   -2.1416483  -1.5315913\n",
      "  -2.7533524  -1.7554419  -1.6189653  -2.6581068  -1.8046939  -1.7635694 ]]\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(val_data.numpy())\n",
    "print(predicted)\n",
    "list_per=[i.tolist().index(np.max(i)) for i in predicted]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 842,
     "status": "ok",
     "timestamp": 1627651219039,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "U61Rdj4oa4LX"
   },
   "outputs": [],
   "source": [
    "def preprocess_dbscale_mel_spectrogram(file):    \n",
    "    audio = tfio.IOTensor.graph(tf.int16).from_audio('/content/drive/MyDrive/test/'+ file)\n",
    "    audio_slice = audio[0:]\n",
    "\n",
    "    # remove last dimension\n",
    "    audio_tensor = tf.squeeze(audio_slice, axis=[-1])\n",
    "    audio_tensor = tf.cast(audio_tensor, tf.float32)\n",
    "\n",
    "    # Convert to spectrogram\n",
    "    spectrogram = tfio.audio.spectrogram(audio_tensor, nfft=2048, window=2048, stride=512)\n",
    "\n",
    "    # Convert to mel-spectrogram\n",
    "    mel_spectrogram = tfio.audio.melscale(spectrogram, rate=48000, mels=384, fmin=40, fmax=24000)\n",
    "\n",
    "    # Convert to db scale mel-spectrogram\n",
    "    mel_spectrogram = tfio.audio.dbscale(mel_spectrogram, top_db=80)\n",
    "\n",
    "    # Expanding the dimensions of spectrograms by 1 \n",
    "    image = tf.expand_dims(mel_spectrogram, axis= -1)\n",
    "    # Resizing the spectrogram\n",
    "    image = tf.image.resize(image, [384, 768])\n",
    "    # Converting the spectrogram to rgb\n",
    "    image = tf.image.grayscale_to_rgb(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 965,
     "status": "ok",
     "timestamp": 1627651225446,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "qTw1ZvM8actp",
    "outputId": "a91b2f58-1297-4086-8d00-47591f6e60c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1992"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=os.listdir('/content/drive/MyDrive/test')\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 752,
     "status": "ok",
     "timestamp": 1627472250372,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "q6xQeq86sbK2",
    "outputId": "9bdfbccf-af69-442f-8a13-6cdd502fcd66"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'7d064b789.flac'"
      ]
     },
     "execution_count": 103,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4792009,
     "status": "ok",
     "timestamp": 1627656022570,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "Se0GaBPYbVOA",
    "outputId": "85ce400a-4a53-4843-9739-8865cdd67610"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [1:19:51<00:00,  2.41s/it]\n"
     ]
    }
   ],
   "source": [
    "test_img=[]\n",
    "for i in tqdm(test_data):\n",
    "  img = preprocess_dbscale_mel_spectrogram(i)\n",
    "  test_img.append(np.array(img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 450,
     "status": "ok",
     "timestamp": 1627476321503,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "8wYqIYXzpg6J",
    "outputId": "57e7d904-bd4c-49fd-bddf-c33da20b1780"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 768, 3)"
      ]
     },
     "execution_count": 105,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img[1991].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2934361,
     "status": "ok",
     "timestamp": 1627659329341,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "KiQZkqwyqE35",
    "outputId": "5df693e8-5c16-45db-d12f-6408dc473280"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [48:53<00:00,  1.47s/it]\n"
     ]
    }
   ],
   "source": [
    "predicted_test_data=[]\n",
    "for i in tqdm(test_img):\n",
    "  pred_model_densenet = model_densenet.predict(np.expand_dims(i, axis = 0))\n",
    "  pred_model_efficientnet = model_efficientnet.predict(np.expand_dims(i, axis = 0))\n",
    "  pred = (pred_model_densenet + pred_model_efficientnet) / 2\n",
    "  predicted_test_data.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1627656048855,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "Bsta9gSW3EIZ",
    "outputId": "d27cdca5-3a7c-46e7-e4c5-c54e35b416ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.18134558, -2.0360067 , -1.7865393 , -1.6968014 , -2.39083   ,\n",
       "         -1.9014617 , -3.3416235 , -2.8074446 , -1.7969773 , -2.2332344 ,\n",
       "         -3.2413802 , -3.3307774 , -1.3197768 , -2.5462008 , -2.4632893 ,\n",
       "         -2.7271402 , -3.0958185 , -2.9717054 , -1.2624395 , -2.6299715 ,\n",
       "         -2.8140783 , -2.669487  , -2.4927018 , -2.9151163 ]],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9H49tQ1r0csr"
   },
   "outputs": [],
   "source": [
    "from numpy import savez_compressed\n",
    "\n",
    "savez_compressed('/content/drive/MyDrive/predicted_test_data.npz', predicted_test_data)\n",
    "\n",
    "savez_compressed('/content/drive/MyDrive/test_data.npz', test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 744,
     "status": "ok",
     "timestamp": 1627659407820,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "BXlVPGFjzbp7"
   },
   "outputs": [],
   "source": [
    "predicted_test_data_new=np.squeeze(predicted_test_data, axis=(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 592,
     "status": "ok",
     "timestamp": 1627236367902,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "d2HHW5vl10WH",
    "outputId": "c977c692-adf3-4204-89d3-078751fbc865"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.77221954, -1.9855454 , -2.5401676 , -1.3586137 , -1.716683  ,\n",
       "       -2.3526776 , -3.630341  , -3.816938  , -1.6501678 , -2.974076  ,\n",
       "       -3.7760692 , -4.2330694 , -0.8994869 , -2.1062174 , -2.7587116 ,\n",
       "       -3.3841586 , -2.9429111 , -3.2152195 , -1.0073056 , -2.9127116 ,\n",
       "       -3.688004  , -2.613102  , -2.648941  , -2.4840145 ], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predicted_test_data_new[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 748,
     "status": "ok",
     "timestamp": 1627659411445,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "We52QKys2hdd"
   },
   "outputs": [],
   "source": [
    "column=['s0','s1'\t,'s2'\t,'s3',\t's4',\t's5'\t,'s6','s7',\t's8',\t's9',\t's10',\t's11',\t's12',\t's13',\t's14',\t's15'\t,'s16',\t's17'\t,'s18',\t's19'\t,'s20',\t's21',\t's22',\t's23']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1627659414050,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "vpri55zOztIR"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=predicted_test_data_new,index = test_data,columns=column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "executionInfo": {
     "elapsed": 682,
     "status": "ok",
     "timestamp": 1627659417913,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "m7sCOi232DhU",
    "outputId": "cf9c5a9b-0d60-4c9a-cc9f-144989d4ff97"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s0</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>s7</th>\n",
       "      <th>s8</th>\n",
       "      <th>s9</th>\n",
       "      <th>s10</th>\n",
       "      <th>s11</th>\n",
       "      <th>s12</th>\n",
       "      <th>s13</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>s22</th>\n",
       "      <th>s23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7d064b789.flac</th>\n",
       "      <td>-0.181346</td>\n",
       "      <td>-2.036007</td>\n",
       "      <td>-1.786539</td>\n",
       "      <td>-1.696801</td>\n",
       "      <td>-2.390830</td>\n",
       "      <td>-1.901462</td>\n",
       "      <td>-3.341624</td>\n",
       "      <td>-2.807445</td>\n",
       "      <td>-1.796977</td>\n",
       "      <td>-2.233234</td>\n",
       "      <td>-3.241380</td>\n",
       "      <td>-3.330777</td>\n",
       "      <td>-1.319777</td>\n",
       "      <td>-2.546201</td>\n",
       "      <td>-2.463289</td>\n",
       "      <td>-2.727140</td>\n",
       "      <td>-3.095819</td>\n",
       "      <td>-2.971705</td>\n",
       "      <td>-1.262439</td>\n",
       "      <td>-2.629972</td>\n",
       "      <td>-2.814078</td>\n",
       "      <td>-2.669487</td>\n",
       "      <td>-2.492702</td>\n",
       "      <td>-2.915116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7d4c75228.flac</th>\n",
       "      <td>-1.117904</td>\n",
       "      <td>-2.276394</td>\n",
       "      <td>-1.974131</td>\n",
       "      <td>-1.508851</td>\n",
       "      <td>-1.588506</td>\n",
       "      <td>-1.755278</td>\n",
       "      <td>-2.750446</td>\n",
       "      <td>-2.583918</td>\n",
       "      <td>-1.839616</td>\n",
       "      <td>-2.080136</td>\n",
       "      <td>-3.014987</td>\n",
       "      <td>-2.974391</td>\n",
       "      <td>-0.631959</td>\n",
       "      <td>-2.881556</td>\n",
       "      <td>-2.192395</td>\n",
       "      <td>-2.485193</td>\n",
       "      <td>-3.001122</td>\n",
       "      <td>-3.001638</td>\n",
       "      <td>-0.968302</td>\n",
       "      <td>-2.394103</td>\n",
       "      <td>-2.717012</td>\n",
       "      <td>-2.469282</td>\n",
       "      <td>-2.166744</td>\n",
       "      <td>-2.016168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7dafb75e0.flac</th>\n",
       "      <td>-1.543853</td>\n",
       "      <td>-2.609704</td>\n",
       "      <td>-1.661935</td>\n",
       "      <td>-1.421255</td>\n",
       "      <td>-2.053091</td>\n",
       "      <td>-1.055067</td>\n",
       "      <td>-2.215418</td>\n",
       "      <td>-2.254807</td>\n",
       "      <td>-2.152347</td>\n",
       "      <td>-2.290104</td>\n",
       "      <td>-2.308115</td>\n",
       "      <td>-2.512888</td>\n",
       "      <td>-1.270482</td>\n",
       "      <td>-2.770142</td>\n",
       "      <td>-2.356285</td>\n",
       "      <td>-2.346637</td>\n",
       "      <td>-2.956211</td>\n",
       "      <td>-2.839258</td>\n",
       "      <td>-1.710155</td>\n",
       "      <td>-1.922762</td>\n",
       "      <td>-2.507324</td>\n",
       "      <td>-2.901019</td>\n",
       "      <td>-1.847933</td>\n",
       "      <td>-1.606109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7d188d367.flac</th>\n",
       "      <td>-1.563805</td>\n",
       "      <td>-2.266073</td>\n",
       "      <td>-1.798391</td>\n",
       "      <td>-1.462778</td>\n",
       "      <td>-1.574582</td>\n",
       "      <td>-1.875902</td>\n",
       "      <td>-2.465223</td>\n",
       "      <td>-2.356843</td>\n",
       "      <td>-2.036975</td>\n",
       "      <td>-1.927291</td>\n",
       "      <td>-3.010244</td>\n",
       "      <td>-2.876614</td>\n",
       "      <td>-0.605860</td>\n",
       "      <td>-2.785285</td>\n",
       "      <td>-2.011417</td>\n",
       "      <td>-2.091562</td>\n",
       "      <td>-2.753160</td>\n",
       "      <td>-2.688542</td>\n",
       "      <td>-1.047076</td>\n",
       "      <td>-2.187098</td>\n",
       "      <td>-2.494048</td>\n",
       "      <td>-2.489937</td>\n",
       "      <td>-2.086056</td>\n",
       "      <td>-2.138624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7e14bfa8e.flac</th>\n",
       "      <td>-4.015090</td>\n",
       "      <td>-3.255013</td>\n",
       "      <td>-4.451508</td>\n",
       "      <td>-2.345621</td>\n",
       "      <td>-3.632944</td>\n",
       "      <td>-2.757291</td>\n",
       "      <td>-2.691586</td>\n",
       "      <td>-1.537498</td>\n",
       "      <td>-2.951644</td>\n",
       "      <td>-4.125506</td>\n",
       "      <td>0.894112</td>\n",
       "      <td>-2.683210</td>\n",
       "      <td>-5.175931</td>\n",
       "      <td>-3.140952</td>\n",
       "      <td>-2.838866</td>\n",
       "      <td>-1.400273</td>\n",
       "      <td>-3.051259</td>\n",
       "      <td>-2.999346</td>\n",
       "      <td>-4.081250</td>\n",
       "      <td>-2.494700</td>\n",
       "      <td>-3.400139</td>\n",
       "      <td>-2.881124</td>\n",
       "      <td>-2.344611</td>\n",
       "      <td>-2.070969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7c3f80ebe.flac</th>\n",
       "      <td>0.304051</td>\n",
       "      <td>-2.114228</td>\n",
       "      <td>-1.730165</td>\n",
       "      <td>-1.664178</td>\n",
       "      <td>-3.041821</td>\n",
       "      <td>-1.836403</td>\n",
       "      <td>-3.693714</td>\n",
       "      <td>-2.736755</td>\n",
       "      <td>-1.809325</td>\n",
       "      <td>-2.320501</td>\n",
       "      <td>-3.220625</td>\n",
       "      <td>-3.538252</td>\n",
       "      <td>-1.530428</td>\n",
       "      <td>-2.872643</td>\n",
       "      <td>-2.750135</td>\n",
       "      <td>-2.906721</td>\n",
       "      <td>-3.407407</td>\n",
       "      <td>-3.071846</td>\n",
       "      <td>-1.515290</td>\n",
       "      <td>-2.896374</td>\n",
       "      <td>-2.966729</td>\n",
       "      <td>-3.177056</td>\n",
       "      <td>-2.480542</td>\n",
       "      <td>-3.298629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7c424b3c9.flac</th>\n",
       "      <td>-3.307044</td>\n",
       "      <td>-2.434880</td>\n",
       "      <td>-3.138282</td>\n",
       "      <td>-1.985147</td>\n",
       "      <td>-2.200586</td>\n",
       "      <td>-2.426800</td>\n",
       "      <td>-3.496834</td>\n",
       "      <td>-3.026733</td>\n",
       "      <td>-2.657478</td>\n",
       "      <td>-2.644892</td>\n",
       "      <td>-3.048644</td>\n",
       "      <td>-3.554491</td>\n",
       "      <td>-2.495568</td>\n",
       "      <td>0.117452</td>\n",
       "      <td>-2.248529</td>\n",
       "      <td>-2.396033</td>\n",
       "      <td>-2.943964</td>\n",
       "      <td>-3.118511</td>\n",
       "      <td>-2.758161</td>\n",
       "      <td>-2.497287</td>\n",
       "      <td>-3.084730</td>\n",
       "      <td>-2.653075</td>\n",
       "      <td>-2.376633</td>\n",
       "      <td>-2.625860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7c3b73585.flac</th>\n",
       "      <td>-2.074891</td>\n",
       "      <td>-2.386307</td>\n",
       "      <td>-1.268996</td>\n",
       "      <td>-1.338863</td>\n",
       "      <td>-2.231519</td>\n",
       "      <td>-1.679492</td>\n",
       "      <td>-2.117013</td>\n",
       "      <td>-1.485750</td>\n",
       "      <td>-2.614358</td>\n",
       "      <td>-2.127113</td>\n",
       "      <td>-2.456430</td>\n",
       "      <td>-2.165810</td>\n",
       "      <td>-1.742610</td>\n",
       "      <td>-2.851687</td>\n",
       "      <td>-2.373562</td>\n",
       "      <td>-1.693890</td>\n",
       "      <td>-2.669604</td>\n",
       "      <td>-2.288677</td>\n",
       "      <td>-2.107257</td>\n",
       "      <td>-2.148349</td>\n",
       "      <td>-1.945663</td>\n",
       "      <td>-3.271209</td>\n",
       "      <td>-1.865221</td>\n",
       "      <td>-1.684505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7cfaed5a0.flac</th>\n",
       "      <td>-1.172880</td>\n",
       "      <td>-2.158128</td>\n",
       "      <td>-1.968047</td>\n",
       "      <td>-1.516912</td>\n",
       "      <td>-1.426354</td>\n",
       "      <td>-1.952752</td>\n",
       "      <td>-2.648178</td>\n",
       "      <td>-2.496339</td>\n",
       "      <td>-1.781976</td>\n",
       "      <td>-2.019371</td>\n",
       "      <td>-2.965409</td>\n",
       "      <td>-2.875727</td>\n",
       "      <td>-0.717689</td>\n",
       "      <td>-2.698814</td>\n",
       "      <td>-2.154322</td>\n",
       "      <td>-2.259155</td>\n",
       "      <td>-2.967951</td>\n",
       "      <td>-2.873453</td>\n",
       "      <td>-0.901298</td>\n",
       "      <td>-2.375186</td>\n",
       "      <td>-2.619760</td>\n",
       "      <td>-2.300500</td>\n",
       "      <td>-2.125462</td>\n",
       "      <td>-2.178924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7bfe229c1.flac</th>\n",
       "      <td>-2.081437</td>\n",
       "      <td>-2.385665</td>\n",
       "      <td>-1.991812</td>\n",
       "      <td>-1.424959</td>\n",
       "      <td>-2.182152</td>\n",
       "      <td>-1.331868</td>\n",
       "      <td>-1.651096</td>\n",
       "      <td>-1.832143</td>\n",
       "      <td>-2.342849</td>\n",
       "      <td>-1.899555</td>\n",
       "      <td>-1.923531</td>\n",
       "      <td>-1.828219</td>\n",
       "      <td>-1.930123</td>\n",
       "      <td>-2.925559</td>\n",
       "      <td>-2.207213</td>\n",
       "      <td>-2.010786</td>\n",
       "      <td>-2.709146</td>\n",
       "      <td>-2.007979</td>\n",
       "      <td>-2.084091</td>\n",
       "      <td>-1.628889</td>\n",
       "      <td>-1.888145</td>\n",
       "      <td>-2.750408</td>\n",
       "      <td>-1.665535</td>\n",
       "      <td>-1.833897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1992 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      s0        s1        s2  ...       s21       s22       s23\n",
       "7d064b789.flac -0.181346 -2.036007 -1.786539  ... -2.669487 -2.492702 -2.915116\n",
       "7d4c75228.flac -1.117904 -2.276394 -1.974131  ... -2.469282 -2.166744 -2.016168\n",
       "7dafb75e0.flac -1.543853 -2.609704 -1.661935  ... -2.901019 -1.847933 -1.606109\n",
       "7d188d367.flac -1.563805 -2.266073 -1.798391  ... -2.489937 -2.086056 -2.138624\n",
       "7e14bfa8e.flac -4.015090 -3.255013 -4.451508  ... -2.881124 -2.344611 -2.070969\n",
       "...                  ...       ...       ...  ...       ...       ...       ...\n",
       "7c3f80ebe.flac  0.304051 -2.114228 -1.730165  ... -3.177056 -2.480542 -3.298629\n",
       "7c424b3c9.flac -3.307044 -2.434880 -3.138282  ... -2.653075 -2.376633 -2.625860\n",
       "7c3b73585.flac -2.074891 -2.386307 -1.268996  ... -3.271209 -1.865221 -1.684505\n",
       "7cfaed5a0.flac -1.172880 -2.158128 -1.968047  ... -2.300500 -2.125462 -2.178924\n",
       "7bfe229c1.flac -2.081437 -2.385665 -1.991812  ... -2.750408 -1.665535 -1.833897\n",
       "\n",
       "[1992 rows x 24 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 633,
     "status": "ok",
     "timestamp": 1627659435399,
     "user": {
      "displayName": "ASHUTOSH BHAYDE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ1ELycNEHGnTBWizvKPQgAnuDYs9bbTxXR3iNCg=s64",
      "userId": "11915394628932936943"
     },
     "user_tz": -330
    },
    "id": "lwFaBiAk3ZDM"
   },
   "outputs": [],
   "source": [
    "df.to_csv('/content/drive/MyDrive/kaggle_test_rainforest_2.csv')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Audio_detection_v3 (3).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
